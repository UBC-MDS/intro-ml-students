{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Machine Learning  \n",
    "\n",
    "## Assignment 4: Similarity-based Approaches to Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't learn technical subjects without hands-on practice. The assignments are an important part of the course. To submit this assignment you will need to make sure that you save your Jupyter notebook. \n",
    "\n",
    "Below are the links of 2 videos that explain:\n",
    "\n",
    "1. [How to save your Jupyter notebook](https://youtu.be/0aoLgBoAUSA) and,       \n",
    "2. [How to answer a question in a Jupyter notebook assignment](https://youtu.be/7j0WKhI3W4s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Learning Goals:\n",
    "\n",
    "By the end of the module, students are expected to:\n",
    "\n",
    "- Explain the notion of similarity-based algorithms.\n",
    "- Broadly describe how ùëò-NNs use distances.\n",
    "- Describe the effect of using a small/large value of the hyperparameter ùëò when using the ùëò-NN algorithm.\n",
    "- Explain the problem of curse of dimensionality.\n",
    "- Explain the general idea of SVMs with RBF kernel.\n",
    "- Compare and contrast ùëò-NNs and SVM RBFs.\n",
    "- Broadly describe the relation of `gamma` and `C` hyperparameters with the fundamental tradeoff.\n",
    "\n",
    "This assignment covers [Module 4](https://ml-learn.mds.ubc.ca/en/module4) of the online course. You should complete this module before attempting this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any place you see `...`, you must fill in the function, variable, or data to complete the code. Substitute the `None` with your completed code and answers then proceed to run the cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the questions in this assignment will have hidden tests. This means that no feedback will be given as to the correctness of your solution. It will be left up to you to decide if your answer is sufficiently correct. These questions are worth 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed for this lab\n",
    "from hashlib import sha1\n",
    "\n",
    "import altair as alt\n",
    "# import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from altair_saver import save\n",
    "\n",
    "from IPython.display import HTML\n",
    "from sklearn import tree\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import test_assignment4 as t\n",
    "#alt.renderers.enable('png')\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Splitting and Exploring Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next few questions, we are going to concentrate on wine data obtained from [Kaggle](https://www.kaggle.com/numberswithkartik/red-white-wine-dataset) that examines the different measurements of wine and we will be attempting to predict if each example is of the red or white variety.  \n",
    "\n",
    "The features in this dataset include: \n",
    "\n",
    "- `fixed_acidity`     \n",
    "- `volatile_acidity`    \n",
    "- `citric_acid`    \n",
    "- `residual_sugar`    \n",
    "- `chlorides`   \n",
    "- `free_sulfur_dioxide`   \n",
    "- `total_sulfur_dioxide`    \n",
    "- `density`    \n",
    "- `pH`     \n",
    "- `sulphates`    \n",
    "- `alcohol`      \n",
    "- `quality`: (score between 0 and 10)       \n",
    "- `style`       \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv('data/wine.csv')\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1** <br> {points: 1}  \n",
    "\n",
    "How many null values do we have in our dataset? Save your answer in an object named \"null_vals\" and if necessary, use `dropna()` and save over the object named `wine_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ba8766cb21f015771e2285379dc7e4b",
     "grade": false,
     "grade_id": "cell-10c9529908255385",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "null_vals = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a5164660e8e94625fdee6ccefb9ecb9",
     "grade": true,
     "grade_id": "cell-f9d43d234a9961d9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_1(null_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** <br> {points: 1}  \n",
    "\n",
    "Split the data into 80% train and 20% test sets. Name your training split `train_df` and your test split `test_df`. We want to make sure that everyone has the same split so please specify an input argument of `random_state=2020`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "580c062a77f1227ff2049a8a9ac83324",
     "grade": false,
     "grade_id": "cell-a4d5c4d8889dadd8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = None, None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d49b455a6189ac2b92e5852d89b91dab",
     "grade": true,
     "grade_id": "cell-fee66afab86f29d9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_2(train_df,test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** <br> {points: 2}  \n",
    "\n",
    "How many dimensions does this dataset have? Save your answer in an object named `wine_dim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c1e3a739f3f5512c9b3df5af96674f5",
     "grade": false,
     "grade_id": "cell-a0b15983d6371fe2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "wine_dim = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fb4adf8f032a2db255e886aec3a5718",
     "grade": true,
     "grade_id": "cell-5f0295f0b610f3c1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'wine_dim' in globals(\n",
    "), \"Please make sure that your solution is named 'wine_dim'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4** <br> {points: 1}  \n",
    "\n",
    "Using the `wine_train` data, look at the summary statistics produced by `.describe()` and save the results in an object named `wine_described`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1d1e09b556b9bf6eb242e9ef08dad5c",
     "grade": false,
     "grade_id": "cell-41440135b47957e3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "wine_described = None \n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e725d840818a5157c903def872bdec96",
     "grade": true,
     "grade_id": "cell-6826fb9eb2ef7b5a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_4(wine_described)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5** <br> {points: 1}  \n",
    "\n",
    "What is the average pH of the wine for each variant in `train_df`? Save the average red variant pH in an object named `avg_red_ph` and the average white variant as `avg_white_ph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fff3e6523882bb2b59c678e5da00d60",
     "grade": false,
     "grade_id": "cell-e786d1d9a520419d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "avg_red_ph = None\n",
    "avg_white_ph = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e998c492c2517788ac3239dfe0d4131e",
     "grade": true,
     "grade_id": "cell-79fb6e72c1169cdd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_5(avg_red_ph,avg_white_ph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6** <br> {points: 1}  \n",
    "\n",
    "What is the average alcohol of the wine styles in `train_df`? Save the average alcohol content of the red variant in an object named `avg_red_alc` and the average alcohol content in the white variant as `avg_white_alc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b2a2bd0f237b4ce47bf9738eb3c1792",
     "grade": false,
     "grade_id": "cell-58fa4b7e0bd64f30",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "avg_red_alc = None\n",
    "avg_white_alc = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3946b4bcc5e055156c66403ae2dda34",
     "grade": true,
     "grade_id": "cell-ee741df7d0f76ef2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_6(avg_red_alc,avg_white_alc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.7** <br> {points: 1}  \n",
    "\n",
    "Plot a bar chart showing the quantity of each wine style in the `train_df` dataframe. Make sure to give it a title and name your plot style_prop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "460b823e8d03169883a76a5b076e8d3e",
     "grade": false,
     "grade_id": "cell-ec178044bc0efc98",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "style_prop = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4499f037161789c9f44eaebf9456c394",
     "grade": true,
     "grade_id": "cell-ac3106788863404a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_7(style_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Finding the Nearest Neighbours\n",
    "\n",
    "Let's explore the training set a bit more and calculate the distance between examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** <br> {points: 1}  \n",
    "\n",
    "Split up `train_df` and `test_df` into feature and target object and name them respectively `X_train`, `y_train`, `X_test` and `y_test`. Remember that our target value is `style`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36e9d008ff2dcea36288a8ba06cbdbc3",
     "grade": false,
     "grade_id": "cell-dd6a1df90ea06dbe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train = None\n",
    "y_train = None\n",
    "X_test = None\n",
    "y_test = None\n",
    "\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "751363f884659e123e3b7205c2364e81",
     "grade": true,
     "grade_id": "cell-b7e1017d1b114232",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_1(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2** <br> {points: 1}  \n",
    "\n",
    "What are the distances between all the wines in the training set? Save this in an object named `wine_similarities`.\n",
    "\n",
    "*Hint: Make sure you are importing the necessary library.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "168f5638a015967fe9e63a0232d14db6",
     "grade": false,
     "grade_id": "cell-46e79334ec9340d8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "wine_similarities = None\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef07725caea7561786ac7d07dff8772b",
     "grade": true,
     "grade_id": "cell-1b6b243fed077aa2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_2(wine_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3** <br> {points: 1}  \n",
    "\n",
    "Which wine index is most similar to that at index 12? Save the index in an object named `sim_wine12`.\n",
    "\n",
    "*Hint: You'll need to make sure you use `fill_diagonal()`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad640e5569091612737f4e508d184506",
     "grade": false,
     "grade_id": "cell-11af7c0da7a0a7a7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sim_wine12 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17a633f339fed962b5cca65e56cde99a",
     "grade": true,
     "grade_id": "cell-e60dc3e12bed44ab",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_3(sim_wine12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4** <br> {points: 2}  \n",
    "\n",
    "What is the distance between the wine at `sim_wine12` and index 12? \n",
    "\n",
    "Save this in an object named `distance_12`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50380e7a3369e89398b6e524c080af00",
     "grade": false,
     "grade_id": "cell-34fb047bde29a2e4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "distance_12 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1589d387a8411b0fa039d3f9e2a724c",
     "grade": true,
     "grade_id": "cell-0102b43b7b31ee0f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'distance_12' in globals(\n",
    "), \"Please make sure that your solution is named 'distance_12'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5** <br> {points: 1}  \n",
    "\n",
    "A new wine was just released into liquor stores with the following feature vector.\n",
    "\n",
    "```\n",
    "[ 8.3   ,  0.325 ,  0.36  ,  13.3    ,  0.101 , 23.    , 49.    ,\n",
    "        0.9966,  3.56  ,  0.42  , 8.2    ,  7.    ]\n",
    "```\n",
    "\n",
    "Which wine from the training dataset should wine merchants mention that it is most similar to? \n",
    "\n",
    "\n",
    "Save this in an object named `similar_new_wine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "345825a3e2de1ceb85254f5381e2b21b",
     "grade": false,
     "grade_id": "cell-378cbc229b98f339",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "new_wine = [[8.3, 0.325, 0.36, 13.3, 0.101, 23.0, 49.0, 0.9966, 3.56, 0.42, 8.2, 7.0]]\n",
    "similar_new_wine = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9fbb8c811c412ba2fac0737decd3f9a",
     "grade": true,
     "grade_id": "cell-babeed8c48116e50",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_5(similar_new_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6** <br> {points: 1}  \n",
    "\n",
    "How far away is the new wine from the most similar wine in the training dataset? \n",
    "\n",
    "Save this distance in an object named `new_distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1972a8bb38e1adeb643c954b5ab93601",
     "grade": false,
     "grade_id": "cell-ed1c8d4a178deeac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "new_distance = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc8fdaba7a50c3c343d13dd6d7bf13fd",
     "grade": true,
     "grade_id": "cell-a710d9b5cba64dc4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_6(new_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KNN Classifiers with different hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1** <br> {points: 1}  \n",
    "\n",
    "Build a `DummyClassifier` using `strategy = 'most_frequent'` and name it `dummy_model`.\n",
    "\n",
    "Train it on `X_train` and `y_train`. Score it on the train **and** test sets.\n",
    "\n",
    "Save the scores in objects named `dummy_train` and `dummy_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7044e031380665215b06bd9e0016caf",
     "grade": false,
     "grade_id": "cell-56175674d33e4b83",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dummy_model = None\n",
    "dummy_train = None\n",
    "dummy_test = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffcce7c013d9232d1575bdc7cb2a69d9",
     "grade": true,
     "grade_id": "cell-6400a2ce5cf6ee23",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_1(dummy_train,dummy_test,dummy_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** <br> {points: 1} \n",
    "\n",
    "Build a `KNeighborsClassifier` named `knn1` with  `n_neighbors=1`. Cross-validate using `cv=10`. \n",
    "What is the mean training score and the mean validation score? Save each respectively in objects named `knn1_train_score` and `knn1_valid_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b1448a1a41370747a60ffea1fc4fde5",
     "grade": false,
     "grade_id": "cell-d082ff9f8677e274",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "knn1 = None\n",
    "knn1_train_score = None \n",
    "knn1_valid_score = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "\n",
    "print(knn1_train_score)\n",
    "print(knn1_valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33d3c5724a7b39ce87ab902e3abdd568",
     "grade": true,
     "grade_id": "cell-ead8f42605604377",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_2(knn1_train_score,knn1_valid_score,knn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3** <br> {points: 2} \n",
    "\n",
    "Which model has the best training accuracy? \n",
    "\n",
    "A) `DummyClassifier`. \n",
    "\n",
    "B) `KNeighborsClassifier(n_neighbors=1)`. \n",
    "\n",
    "C) Both A and B\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer3_3`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df4930a8821112aa65479997a4944db3",
     "grade": false,
     "grade_id": "cell-c8a5735bea3eced6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer3_3 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer3_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5d85601551d3dfee11bd1621e9fe579",
     "grade": true,
     "grade_id": "cell-e952095fa34aa688",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'answer3_3' in globals(\n",
    "), \"Please make sure that your solution is named 'answer3_3'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4** <br> {points: 1} \n",
    "\n",
    "Which model has the best cross-validation accuracy?\n",
    "\n",
    "A) `DummyClassifier`. \n",
    "\n",
    "B) `KNeighborsClassifier(n_neighbors=1)`. \n",
    "\n",
    "C) Both A and B\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer3_4`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e2e334b4e230fcedfbef6531e49c05f",
     "grade": false,
     "grade_id": "cell-d38ce6cb644a178d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer3_4 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer3_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ad2862192d0c59aa93068514f619749",
     "grade": true,
     "grade_id": "cell-4681939a97b5cd34",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_4(answer3_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5** <br> {points: 1}\n",
    "\n",
    "Which model is probably overfitting?\n",
    "\n",
    "A) `DummyClassifier`\n",
    "\n",
    "B) `KNeighborsClassifier(n_neighbors=1)`\n",
    "\n",
    "C) Both A and B\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer3_5`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37783a399b189c014e28f96a3ef1ea62",
     "grade": false,
     "grade_id": "cell-0c58c9e08aa36ee3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer3_5 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer3_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6320b63b3773ef0b0a19d4a1017daee",
     "grade": true,
     "grade_id": "cell-a385e05dea4f65b8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_5(answer3_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6** <br> {points: 1} \n",
    "\n",
    "***True or False*** \n",
    "\n",
    "For smaller values of $k$ you are expected to get higher training scores. \n",
    "\n",
    "\n",
    "*Answer in the cell below by assigning `True` or `False` to an object called `answer3_6`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1f1ea6cd7ba3cc99cdd5a3dd9caeffa",
     "grade": false,
     "grade_id": "cell-1a9f52986b72f548",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer3_6 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer3_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "406daa464a2a7b03b5d9bdca4b19dca5",
     "grade": true,
     "grade_id": "cell-b4993ec29464ceff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_6(answer3_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7** <br> {points: 1} \n",
    "\n",
    "If we increase the number of features, which of the following is true?\n",
    "\n",
    "A) The training and validation scores will always increase.\n",
    "\n",
    "B) The training and validation scores will always decrease.\n",
    "\n",
    "C) The training and validation scores will decrease when we start adding irrelevant features.\n",
    "\n",
    "D) The model only picks features that it deems important so nothing changes. \n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer3_7`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bc2cfa891dfb4ceaee550ac5afa9153",
     "grade": false,
     "grade_id": "cell-fb881efc3b81b217",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer3_7 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer3_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c6bb8678917f2d372340722874b57b2",
     "grade": true,
     "grade_id": "cell-8036b0174269a4e2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_7(answer3_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8** <br> {points: 3} \n",
    "\n",
    "Now let's do some hyperparameter tuning and find the most optimal value for  `n_neighbors` in our `KNeighborsClassifier`. \n",
    "\n",
    "We want to find the best hyperparameter value to predict on our test set so let's build a loop as we have in the previous assignments where we record the training and cross-validation scores for each hyperparameter value.\n",
    "\n",
    "Create a `for` loop that iterates over `n_neighbors` values from every second number from 2 to 20 (inclusive). We've started this for you.\n",
    "\n",
    "Each iteration should:\n",
    "1. Create a `KKNeighborsClassifier` object with `n_neighbors` changing at each iteration.\n",
    "2. Run 5-fold cross-validation with this value of `n_neighbors` using `cross_validate` to get the mean train and validation accuracies. Make sure to set `return_train_score=True` to get the training score in each fold. \n",
    "3. Appends the `n_neighbors` value to the list in the key `n_neighbors` of the dictionary named `results_dict`.\n",
    "4. Appends the mean `train_score` of the cross-validation folds to the list in the `mean_train_score` dictionary key. \n",
    "5. Appends the mean `test_score` of the cross-validation folds to the list in the `mean_cv_score` dictionary key. \n",
    "\n",
    "(Note that this may take a few minutes to execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c67ba6c19407a501a9355e278674738",
     "grade": false,
     "grade_id": "cell-f699aee3e2255189",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    \"n_neighbors\": [],\n",
    "    \"mean_train_score\": [],\n",
    "    \"mean_cv_score\": []}\n",
    "\n",
    "results_dict\n",
    "\n",
    "for k in range(2,20, 2):\n",
    "    \n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95765e6f1021995081675960b86086e3",
     "grade": true,
     "grade_id": "cell-043b50b06148e168",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_8(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.9** <br> {points: 1} \n",
    "\n",
    "Convert the dictionary `results_dict` into a dataframe and use `pd.melt()` to melt the columns `mean_train_score` and `mean_cv_score` in the `results_df`.  Use `var_name='score_type'` and `value_name='accuracy'` and name the new dataframe `knn_plot_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5da73c134b7670b444bd3e8bc216afc",
     "grade": false,
     "grade_id": "cell-f85064f54b3f81c1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "knn_plot_df = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4eae2c7086a925e9b38f48736ffc14f",
     "grade": true,
     "grade_id": "cell-6b4a79b10555e0d0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_9(knn_plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.10** <br> {points: 1} \n",
    "\n",
    "Using Altair, make a `mark_line()` plot which displays the `n_neighbors` of the KNN model on the *x*-axis and the accuracy on the train and validation sets on the *y*-axis and don't forget to add `alt.Color(score_type)` to the `encode()` function after you specify `alt.X()` and `alt.y()`. \n",
    "\n",
    "Make sure it has the dimensions `width=500, height=300`. Don't forget to give it a title and the plot `knn_plot`.\n",
    "To make things more legible, use `scale=alt.Scale(domain=[.92, 0.98])` in your `alt.Y()` function which will start the y-axis at 0.92 and end it at 0.98. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b47b6909c97eaa8ef6d433ac115f25d",
     "grade": false,
     "grade_id": "cell-8d2e148b8757a698",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "knn_plot = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db5812730ac0167cae0a209e4c937f75",
     "grade": true,
     "grade_id": "cell-b18130ba70ebf0cd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_10(knn_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.11** <br> {points: 1} \n",
    "\n",
    "From your results, what `n_neighbors` would you pick in your final model? Save your answer in an object named `best_k`.\n",
    "\n",
    "*Hint: [<code>.idxmax()</code>](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.idxmax.html) may come in handy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2b91989fc627390cf16cd81f041f105",
     "grade": false,
     "grade_id": "cell-d1aa91f1f2a9e12e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "best_k = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "add54e23a1921b821f00bbeb6967dee8",
     "grade": true,
     "grade_id": "cell-54234e89fba928c0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_11(best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.12** <br> {points: 1} \n",
    "\n",
    "Build a K-Nearest Neighbour classifier named `best_model` with the best `n_neighbors` and fit it with `X_train` and `y_train`. Score your model on the test set and save your results in an object named `test_score`.\n",
    "\n",
    "Is this doing better than your dummy classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec649ddf6a8978ab8b276a9cde93b8cf",
     "grade": false,
     "grade_id": "cell-345637fc0c5bb9ab",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "best_model = None\n",
    "test_score = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f4174bfb6ece9bf6bb6f6477d460bae",
     "grade": true,
     "grade_id": "cell-62e961d390cf7576",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_12(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Support Vector Machines Classifier \n",
    "\n",
    "Up until this point, we have been working with the K-Nearest Neighbour Classifier. Let's shake things up a bit and explore the second model that we learned in this module. Unlike other questions up to this point, we've only explored one hyperparameter at a time. This time let's see how well we can optimize more than one hyperparameter simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1** <br> {points: 0} \n",
    "\n",
    "Import SVC from the appropriate library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccb2790db4e2800db3a8fd0559ab4f9d",
     "grade": true,
     "grade_id": "cell-68cb250142d4712b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2** <br> {points: 1} \n",
    "\n",
    "Repeat the loop you made in **Question 3.8** but this time but this time, tune the hyperparameter `gamma` and find the most optimal value for  `gamma` in an `SVC` model.  \n",
    "\n",
    "We want to find the best gamma value to test our model.\n",
    "Don't forget to set `random_state=2020` so we can confirm your answer. \n",
    "\n",
    "Create a `for` loop that iterates over `gamma` values from 0.1 to 100 (inclusive) that increases exponentially with base 10. (We've started this for you.)\n",
    "\n",
    "To recap the instructions from before, each iteration should:\n",
    "1. Create a `SVC` object with `gamma` changing at each iteration.\n",
    "2. Run 5-fold cross-validation with this value of `gamma` using `cross_validate` to get the mean train and validation accuracies. Make sure to set `return_train_score=True` to get the training score in each fold. \n",
    "3. Appends the `gamma` value to the list in the key `gamma`.\n",
    "4. Appends the mean `train_score` of the cross-validation folds to the list in the `mean_train_score` dictionary key. \n",
    "5. Appends the mean `test_score` of the cross-validation folds to the list in the `mean_cv_score` dictionary key. \n",
    "\n",
    "(Note that this may take quite a few minutes to execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dabf71c54c984abd0795a1d4cb54e87a",
     "grade": false,
     "grade_id": "cell-10133bd9809e5a10",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    \"gamma\": [],\n",
    "    \"mean_train_score\": [],\n",
    "    \"mean_cv_score\": []}\n",
    "\n",
    "results_dict\n",
    "\n",
    "for g in [0.1, 1.0, 10.0, 100.0]:\n",
    "    \n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55e3ca86e7c01f9a6bad391b2cac469d",
     "grade": true,
     "grade_id": "cell-bb1cfb49db39d555",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_2(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3** <br> {points: 1} \n",
    "\n",
    "Which value of gamma would you select for your model. Save your result in an object named `best_gamma`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "669b83ada7c8f73b44ee370dabc1c5c3",
     "grade": false,
     "grade_id": "cell-0b3b382adaca1a03",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "best_gamma = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "best_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59f399d6f5eb6f1bdd4fd428a6ce025c",
     "grade": true,
     "grade_id": "cell-d0448b6aadd07042",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_3(best_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4** <br> {points: 1} \n",
    "\n",
    "Now repeat **Question 4.2**, this time iterating over the hyperparameter C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad5e3f32b8c3637cccb53cfc7962ee8a",
     "grade": false,
     "grade_id": "cell-8904d4a70c2fdab9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    \"C\": [],\n",
    "    \"mean_train_score\": [],\n",
    "    \"mean_cv_score\": []}\n",
    "\n",
    "results_dict\n",
    "\n",
    "for c in [0.1, 1.0, 10.0, 100.0]:\n",
    "    \n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7e60ae03d3c130212fbdf56e0d382e7",
     "grade": true,
     "grade_id": "cell-82a50cb35ec596c4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_4(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5** <br> {points: 1} \n",
    "\n",
    "Which value of `C` would you select for your model now? Save your result in an object named `best_c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "534e6cdafe2bbfed3bc298d6a5a946d3",
     "grade": false,
     "grade_id": "cell-1d8554ebecd4186b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "best_c = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b853bc58c5ef21411612d8ed18878825",
     "grade": true,
     "grade_id": "cell-480d22989fe53d34",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_5(best_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.6** <br> {points: 2} \n",
    "\n",
    "Do you think choosing the value of `Gamma` from question 4.3 and the value of `C` from question 4.5 will produce the best scoring model to run our test set on?  \n",
    "\n",
    "A) No. we should have set `gamma` to `best_gamma` and iterated over the value of `C`. This would have produced the most optimal model. \n",
    "\n",
    "B) No, we should be searching all values of gamma with all values of C since it's possible that hyperparameter values may score lower independently but could score higher when cross-validated together. \n",
    "\n",
    "C) Yes. Both `Gamma` and `C` produced the highest cross-validation scores independently and therefore they must produce the highest cross-validation scores together.   \n",
    "\n",
    "D) Yes. `Gamma` and `C` are not correlated and therefore finding the best values separately will not change how the scores would be if we tested them together. \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer4_6`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b52704b65f3641ccbbf1a5fe04acbdb",
     "grade": false,
     "grade_id": "cell-b4f97303a0416986",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_6 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer4_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e9cf8a49f9bd636388cdee0b6827a7e",
     "grade": true,
     "grade_id": "cell-19317c993ffeaecd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'answer4_6' in globals(\n",
    "), \"Please make sure that your solution is named 'answer4_6'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.7** <br> {points: 2} \n",
    "\n",
    "Write a nested loops to search over gamma and C simultaneously. Use 5 fold cross-validation and append the training and validation (`test_score`) scores to the `param_scores` dictionary. \n",
    "\n",
    "*Note: This could take quite a few minutes to run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3edc945a5271a6a01c65370c10f754ea",
     "grade": false,
     "grade_id": "cell-5bce8adc270f2c78",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"gamma\": [0.1, 1.0, 10.0, 100.0],\n",
    "    \"C\": [0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "param_scores = {\"gamma\": [], \"C\": [], \"train_accuracy\": [], \"valid_accuracy\": []}\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad24192eb147f1c873086f7edea48397",
     "grade": true,
     "grade_id": "cell-32501793b66439d8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_7(param_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.8** <br> {points: 1} \n",
    "\n",
    "Save `param_scores` as a dataframe named `param_scores_df` and sort by validation score in descending order. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8b12000eed09112413443f79b080de0",
     "grade": false,
     "grade_id": "cell-8837e285843df5fc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "param_scores_df = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49a9d67e2faaaaf1d0c0c5ad2e28454e",
     "grade": true,
     "grade_id": "cell-f02849c137a2b3a6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_8(param_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.9** <br> {points: 1} \n",
    "\n",
    "Build your new model name `best_svc` using the values for `gamma` and `C` we obtained when tunning then hyperparameters simultaneously in **Question 4.8**. Set the random_state to 2020 and fit it with `X_train` and `y_train`. Score your model on the test set and save your results in an object named `svc_test_score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5321af6f8474e5a694495bcba61b8b05",
     "grade": false,
     "grade_id": "cell-6a875c1ebf4b403f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "svc_test_score = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9dfd248fe329d8bd8bd89850ef14e235",
     "grade": true,
     "grade_id": "cell-3521a4d025d91485",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_9(svc_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.10** <br> {points: 1} \n",
    "\n",
    "Which model performs better?\n",
    "\n",
    "A) `KNeighborsClassifier`\n",
    "\n",
    "B) `SVC`\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer4_10`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eeede2b160c7e13dd6dc1efdf9c1a3b3",
     "grade": false,
     "grade_id": "cell-0b7e0367af6b1517",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_10 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer4_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "555025e2c5e66a74b7ae2a223c9f8e20",
     "grade": true,
     "grade_id": "cell-a96b1da528717f75",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_10(answer4_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Submitting \n",
    "\n",
    "Before submitting your assignment please do the following:\n",
    "\n",
    "- Read through your solutions\n",
    "- **Restart your kernel and clear output and rerun your cells from top to bottom** \n",
    "- Makes sure that none of your code is broken \n",
    "- Verify that the tests from the questions you answered have obtained the output \"Success\"\n",
    "\n",
    "This is a simple way to make sure that you are submitting all the variables needed to mark the assignment. This method should help avoid losing marks due to changes in your environment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "- Wine dataset - [Kaggle](https://www.kaggle.com/numberswithkartik/red-white-wine-dataset)\n",
    "\n",
    "\n",
    "- MDS DSCI 571 - Supervised Learning I - [MDS's GitHub website](https://github.com/UBC-MDS/DSCI_571_sup-learn-1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
