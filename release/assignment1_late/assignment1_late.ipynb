{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning  \n",
    "\n",
    "## Assignment 1: Machine Learning Fundamentals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't learn technical subjects without hands-on practice. The assignments are an important part of the course. To submit this assignment you will need to make sure that you save your Jupyter notebook. \n",
    "\n",
    "Below are the links of 2 videos that explain:\n",
    "\n",
    "1. [How to save your Jupyter notebook](https://youtu.be/0aoLgBoAUSA) and,       \n",
    "2. [How to answer a question in a Jupyter notebook assignment](https://youtu.be/7j0WKhI3W4s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Learning Goals:\n",
    "\n",
    "By the end of the module, students are expected to:\n",
    "\n",
    "- Explain motivation to study machine learning.\n",
    "- Differentiate between supervised and unsupervised learning.\n",
    "- Differentiate between classification and regression problems.\n",
    "- Explain machine learning terminology such as features, targets, training, and error.\n",
    "- Use DummyClassifier/ Dummy Regressor as a baseline for machine learning problems.\n",
    "- Explain the `.fit()` and `.predict()` paradigm and use `.score()` method of ML models.\n",
    "\n",
    "\n",
    "This assignment covers [Module 1](https://ml-learn.mds.ubc.ca/en/module1) of the online course. You should complete this module before attempting this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any place you see `...`, you must fill in the function, variable, or data to complete the code. Substitute the `None` with your completed code and answers then proceed to run the cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the questions in this assignment will have hidden tests. This means that no feedback will be given as to the correctness of your solution. It will be left up to you to decide if your answer is sufficiently correct. These questions are worth 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed for this lab\n",
    "from hashlib import sha1\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "# import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import test_assignment1 as t\n",
    "from IPython.display import HTML\n",
    "from sklearn import tree\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. About Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1** <br> {points: 1}  \n",
    "\n",
    "Which of the following is **NOT** a type of Machine Learning?\n",
    "\n",
    "\n",
    "To answer the question, assign the letter associated with the correct answer to a variable in the code cell below:   \n",
    " \n",
    "A) Recommender Systems\n",
    "\n",
    "B) Auto-completion \n",
    "\n",
    "C) Microwaves \n",
    "\n",
    "D) Drug Discovery \n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer1_1`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b52ab8a82861469469860f1855d09d16",
     "grade": false,
     "grade_id": "cell-9900d06174d0c0bd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer1_1 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer1_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "659d601d003fdc9d62e10b5c0f97e1f6",
     "grade": true,
     "grade_id": "cell-f6b571257476a333",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_1(answer1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** <br> {points: 1}  \n",
    "\n",
    "The following are different types of machine learning examples, categorize the as either \"Supervised\" or \"Unsupervised\" in a object of the same name.\n",
    "\n",
    "\n",
    "To answer the question, assign the letter associated with the correct answer to a variable in the code cell below:   \n",
    " \n",
    "A) Filtering emails as junk or regular mail. \n",
    "\n",
    "B) Grouping companies customers together on similarity.\n",
    "\n",
    "C) Predicting a student's MCAT grade given the marks they have received on the practice exams. \n",
    "\n",
    "D) Speech recognition (inferring the words from an audio signal of a person's voice)\n",
    "\n",
    "_Assign the examples to objects called `supervised` and `unsupervised` in the code chunk below. Make sure your answer is surrounded by square brackets. If there are more than one answers to this question, separate each number with a comma in the square brackets. For example if you believe that A and B are supervised, C is unsupervised and D is neither, then your answer would look like this:_\n",
    "\n",
    "```\n",
    "supervised = [\"A\", \"B\"]\n",
    "unsupervised = [\"A\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86e103157dfcc9b52127d8ec33e7e3dd",
     "grade": false,
     "grade_id": "cell-b3faa1e7ad6637cd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "supervised = [\"A\", \"B\"]\n",
    "unsupervised = [\"A\"]\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "[supervised,unsupervised]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "276d0677c5a7511b87f93e26a6d935d1",
     "grade": true,
     "grade_id": "cell-add0521fb6a0a00d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_2(supervised,unsupervised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** <br> {points: 4}  \n",
    "\n",
    "In the next 3 situations, would the problem be considered ***regression*** or ***classification***? \n",
    "\n",
    "\n",
    "i) Based on the ingredients in a store, categorizing it as breakfast food, lunch food, dinner food.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ii) Estimating the fiber content in different types of bread based on the ingredients.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "iii) The dataset below (with the target column being `number_comments`: \n",
    "\n",
    "|   | video_name| number_views |number_likes |number_dislikes| time_since_upload |number_comments|\n",
    "|--:|:----------|:----------------|:---------------|:-----------------|:------------------|:-----------------|\n",
    "|**0**| Cute kitten purring  |  345602  | 3743 | 89 | 5603 | 6 | \n",
    "|**1**| How to make guacamole  |  56777032  | 69327 | 3405 | 25793 | 107 | \n",
    "|**2**| Pool trick shots  |  2458602  | 23743 | 40622 | 104802 | ? | \n",
    "|**3**| Light show  |  103  | 3 | 1 | 300 | ? | \n",
    "|**4**|  Edward Snowden  |  603042  | 1502 | 62 | 315360 | ? | \n",
    "\n",
    "<br>\n",
    "\n",
    "*Save your answers as a string in an object named as `answer1_3_a`, `answer1_3_b` and  '`answer1_3_c` respectively.*   \n",
    "Example:\n",
    "\n",
    "```\n",
    "answer1_3_a = \"Regression\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8bdaf3f7368e43b59f295de745af21c",
     "grade": false,
     "grade_id": "cell-069b76ec95926250",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer1_3_a = None\n",
    "answer1_3_b = None\n",
    "answer1_3_c = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "282c093b762762b2a04cdf3e269dc20d",
     "grade": true,
     "grade_id": "cell-0cc73fbf17f3aac8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'answer1_3_a' in globals(\n",
    "), \"Please make sure that your solution is named 'answer1_3_a'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68d42e16269c154de700387a77919ff0",
     "grade": true,
     "grade_id": "cell-a2dcf5b946530d15",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_3_2(answer1_3_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b91da33b8504e1f816ea5380ec4c2c7",
     "grade": true,
     "grade_id": "cell-ca3aeea0ffe74e73",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_3_3(answer1_3_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** \n",
    "<br> {points: 5}\n",
    "\n",
    "For this next section, as per the lecture notes, give a synonym for each term.\n",
    "\n",
    "Example:\n",
    "\n",
    "`observations = \"examples\"`\n",
    "\n",
    "*Save your answers as a string in the respective object name aka `rows`, `columns`, `target` and  `training` respectively.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf32aa1e80049924e0dc4a2b725891bd",
     "grade": false,
     "grade_id": "cell-016cb5fedeb0c8cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "rows = None\n",
    "inputs = None \n",
    "outputs = None\n",
    "training = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1bd4a19ff24393ab5c453c2c90c9980",
     "grade": true,
     "grade_id": "cell-3a995a508001fa13",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_1_1(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d588ab10ec91f5e7143f78c6dd6c8f4d",
     "grade": true,
     "grade_id": "cell-7fe5f906a5aa7ea2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_1_2(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fd0bb3c90a5744bf85cbcc5279f9df5",
     "grade": true,
     "grade_id": "cell-c051eaae22b62cec",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'outputs' in globals(\n",
    "), \"Please make sure that your solution is named 'outputs'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "799c92dc46b2155a573e17fdc3073de2",
     "grade": true,
     "grade_id": "cell-be5d4bdbf81c0311",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_1_4(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2** \n",
    "\n",
    "Below is a toy data set that we will be using to get familiar with scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_data = {\n",
    "    # Features\n",
    "    'is_sweet': [0, 0, 1, 1, 0, 1, 0],\n",
    "    'diameter': [3, 3, 1, 1, 3, 1, 4],\n",
    "    # Target\n",
    "    'target': ['Apple', 'Apple', 'Grape', 'Grape', 'Lemon', 'Grape', 'Apple']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(toy_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2(a)** \n",
    "<br> {points: 1}\n",
    "\n",
    "How many features are present in the dataset? \n",
    "\n",
    "*Assign your answer to a variable of type `int` called `answer2_2_a`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba7aaf351b41bee9a68673ae49473172",
     "grade": false,
     "grade_id": "cell-93b1d48c76d17000",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_2_a = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer2_2_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "462fe6d420692d812491e2c65e3cf273",
     "grade": true,
     "grade_id": "cell-361b06792ae5c6c2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_2a(answer2_2_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2(b)** \n",
    "<br> {points: 1}\n",
    "\n",
    "Express the names of the features as strings in a list. ex `[\"Feature1\", \"Feature2\", \"Feature3\"]`\n",
    "\n",
    "*Assign your answer to a variable called `answer2_2_b`.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dead4bb288d24ea450cf50bff55d07d3",
     "grade": false,
     "grade_id": "cell-cc3615e94a2e2582",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_2_b = None\n",
    "\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer2_2_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94360f4cf071f70dc41d8bb2b6929326",
     "grade": true,
     "grade_id": "cell-9586ffb932553194",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_2b(answer2_2_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2(c)** \n",
    "<br> {points: 1}\n",
    "\n",
    "How many different target classes (categories) are present in the dataset? *Assign your answer to a variable of type `int` called `answer2_2_c`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e0881a10f16c5a415df1765687bfd52",
     "grade": false,
     "grade_id": "cell-5f7346031ac30130",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_2_c = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer2_2_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d24ee31177ee12f85302672086002b10",
     "grade": true,
     "grade_id": "cell-741abfe2b2c5668b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_2c(answer2_2_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. More Terminology "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next 3 questions we will be working with data that was obtained from [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Fertility) that examines the fertility among males between the ages of 18-36. The data was provided by 100 volunteers who provided a sample and was analyzed according to the WHO 2010 criteria. \n",
    "We have modified this dataset so that it is easier to work with in this assignment. \n",
    "\n",
    "The columns in the dataset can be explained as follows: \n",
    "\n",
    "\n",
    "- `age`: Age at the time of analysis. 18-36 \n",
    "\n",
    "- `diseases`:  Has the respondent had any childhood diseases (ie , chicken pox, measles, mumps, polio) (No: 0, Yes: 1)(0, 1)\n",
    "\n",
    "- `accident`: Has the respondent had an accident or serious trauma? (No: 0, Yes: 1)\n",
    "\n",
    "- `surgical_inter`:  Has the respondent had any surgical intervention (No: 0, Yes: 1)\n",
    "\n",
    "- `fever`: Has the respondent had high fevers in the last year?  (Less than three months ago: -1, More than three months ago:0, No: 1)\n",
    "\n",
    "- `alcohol`: What is the respondent's frequency of alcohol consumption? (Several times a day: 0.2, Every day:  0.4, Several times a week: 0.6, Once a week: 0.8, Hardly ever or never: 1) \n",
    "\n",
    "- `smoking_level`: Smoking habit 1) never, 2) occasional 3) daily (-1, 0, 1)\n",
    "\n",
    "- `sitting_time`: Number of hours spent sitting per day (Minumum value:0, Maximum value: 1)\n",
    "\n",
    "- `diagnosis`: Output: Diagnosis normal (N), altered (O)\n",
    "\n",
    "\n",
    "The column `diagnosis` is our target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fertility_df = pd.read_csv('data/fertility_diagnosis.csv')\n",
    "fertility_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1** \n",
    "<br> {points: 1}\n",
    "\n",
    "How many features are there? \n",
    "\n",
    "*Assign the correct answer to an object of type `int` called `feature_num`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db03d8e5d0ec09377af804b8da6a8f6f",
     "grade": false,
     "grade_id": "cell-8298e78e019acbaf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "feature_num = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "feature_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83ef6ed14a38d715970e4c626f8f0714",
     "grade": true,
     "grade_id": "cell-196048fd0dc0f574",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_1(feature_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** \n",
    "<br> {points: 2}\n",
    "\n",
    "What type of problem is this ***Regression*** or ***Classification***?\n",
    "\n",
    "*Answer in the cell below with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `problem`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f7dbdfcebfd2affa9c81ddae2855878",
     "grade": false,
     "grade_id": "cell-ab02d8045dbe04fe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "problem = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0704d1a1d038cb13042298d117768caf",
     "grade": true,
     "grade_id": "cell-6e5044a5e2caa4a2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'problem' in globals(\n",
    "), \"Please make sure that your solution is named 'problem'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3** \n",
    "<br> {points: 1}\n",
    "\n",
    "Create your $X$ and $y$ dataframes based on the answers to the questions above.\n",
    "\n",
    "*Save each in the respective object names `X` and `y`* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13c185aa8ebbce1c43cf3e6d2bf96326",
     "grade": false,
     "grade_id": "cell-cb9f83b7d9fb121c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = None\n",
    "y = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6210ff5092503377051e8f3e3540cf6c",
     "grade": true,
     "grade_id": "cell-bef644d0adf46d07",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_3(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Dummy Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question we are going to explore the accuracy of different dummy classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1** \n",
    "<br> {points: 0}\n",
    "\n",
    "Import the `DummyClassifier()` from the `from sklearn.dummy` library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a755989d7ac19b8575b45c7490b24bed",
     "grade": false,
     "grade_id": "cell-469b2ffd9cbeb846",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5fdd7d565fe548f8b9b46b38e423cca",
     "grade": true,
     "grade_id": "cell-fe4bb3ace4157bda",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2** \n",
    "<br> {points: 1}\n",
    "\n",
    "Build a Dummy Classifier with the `strategy` \"stratified\" and name it `strat_clf`.     \n",
    "Make sure to specify a second argument `random_state=1`. This just makes sure every student will produce the same model and remove and randomness. \n",
    "\n",
    "The *stratified* `strategy` argument value generates predictions by respecting the training set’s class distribution. This means that if a target category only exists 5 times out of 100 examples, the dummy classifier will only predict the category 5% of the time.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f753f597185e981a332ac9e6153c2538",
     "grade": false,
     "grade_id": "cell-e21e632f5d4cd90e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "strat_clf = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "832e85b49692a05573ae383465965ae6",
     "grade": true,
     "grade_id": "cell-5ab0893ea3a96524",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_2(strat_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3** \n",
    "<br> {points: 1}\n",
    "\n",
    "Train `strat_clf` on the `X` and `y` objects we made in question 4.2.\n",
    "\n",
    "Predict on `y`  and save this in an object named `strat_predicted`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fbc9423ca422098f096e44d6ffaca69",
     "grade": false,
     "grade_id": "cell-8b44c4e5194d84e5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "strat_predicted = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "906581d5d1c8aca5fdccd644cea58e68",
     "grade": true,
     "grade_id": "cell-4dffe172aa3ec860",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_3(strat_clf,strat_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4** \n",
    "<br> {points: 2}\n",
    "\n",
    "What is the accuracy of this model? \n",
    "\n",
    "Save the result to 2 decimal places in an object named `strat_accuracy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96039cf0cf78fe9ab2be192198d986de",
     "grade": false,
     "grade_id": "cell-6252f8228ff4565b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "strat_accuracy = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "\n",
    "strat_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe684c2b94e54f8b3cfb5a35089be039",
     "grade": true,
     "grade_id": "cell-f09ea530f19e6f31",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'strat_accuracy' in globals(\n",
    "), \"Please make sure that your solution is named 'strat_accuracy'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5** \n",
    "<br> {points: 1}\n",
    "\n",
    "We can train different models and compare which ones are the most accurate using a `for` loop. \n",
    "\n",
    "For this question make a `for` loop that loops over the values \"stratified\", \"most_frequent\" and \"uniform\", builds a model, trains and scores each model and save the accuracy to 2 decimal places in a new list called `accuracies`.\n",
    "\n",
    "\n",
    "Make sure to specify a second argument `random_state=1` for the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dffe43318481ba12411a893cd457c39",
     "grade": false,
     "grade_id": "cell-bc8eb0f911c1fe33",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "strategies = [\"stratified\", \"most_frequent\", \"uniform\"]\n",
    "accuracies = list()\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "set(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc4dcef9b42da9ad36e04e27275a23e6",
     "grade": true,
     "grade_id": "cell-662cf483fa41c124",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_5(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.6** \n",
    "<br> {points: 1}\n",
    "\n",
    "Create a new dataframe name `accuracies_df` made from the lists `strategies` and `accuracies`. \n",
    "It should look like this:\n",
    "\n",
    "|    | strategy      |   accuracy |\n",
    "|---:|:--------------|-----------:|\n",
    "|  0 | stratified    |       #    |\n",
    "|  1 | most_frequent |       #    |\n",
    "|  2 | uniform       |       #    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a8fea1db7526a054360a5b9bdc56593",
     "grade": false,
     "grade_id": "cell-52082c4f7ff809a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "accuracies_df = None \n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "accuracies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fecd99349bc45cce42b91d1a4b19d000",
     "grade": true,
     "grade_id": "cell-40050884834982f6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_6(accuracies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.7** \n",
    "<br> {points: 1}\n",
    "\n",
    "Using Altair, make a bar plot (`mark_bar()`) that displays the `strategy` on the x-axis and the `accuracy` on the y-axis. Don't forget to give it a title and to sort it in ascending order. Make sure it has the dimensions `width=500, height=300`. \n",
    "Name the plot `Dummy_plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a1a4dd157fd5a4108222a328fa74ef4",
     "grade": false,
     "grade_id": "cell-e5946eeeed14caf7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Dummy_plot = None\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "Dummy_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56e01ec4a8190164fb200bbdec9f017c",
     "grade": true,
     "grade_id": "cell-877dd5d29416fea2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_7(Dummy_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.8** \n",
    "<br> {points: 1}\n",
    "\n",
    "Which strategy had the best results? \n",
    "\n",
    "\n",
    "To answer the question, assign the letter associated with the correct answer to a variable in the code cell below:   \n",
    " \n",
    "A) `stratified`\n",
    "\n",
    "B) `most_frequent` \n",
    "\n",
    "C) `uniform`\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer4_8`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20e32b84304aa49ab5fcb5c503a221b7",
     "grade": false,
     "grade_id": "cell-59a706bea7e774f4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_8 = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer4_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64cc7b0480c90c9425a9d1554abdea08",
     "grade": true,
     "grade_id": "cell-e2b406c00fd688a1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_8(answer4_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Dummy Regressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time instead of focusing on a classification problem we are going to focus on a regression problem using the `DummyRegressor` baseline model. \n",
    "\n",
    "For this question we are using a dataset obtained from [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set) that contains the market historical data of real estate valuation collected from Sindian District, New Taipei City in Taiwan.\n",
    "\n",
    "The columns in the dataset can be explained as follows: \n",
    "\n",
    "- `date`: the transaction date (for example, 2013.250=2013 March, 2013.500=2013 June, etc.)\n",
    "- `house_age`: the house age (unit: year)\n",
    "- `distance_station`: the distance to the nearest Mass Rapid Transit (MRT) station (unit: meter)\n",
    "- `num_stores`: the number of convenience stores in the living circle on foot (integer)(a ***living circle*** is a residential space with similar local characteristics, and daily behaviors)\n",
    "- `latitude`: the geographic coordinate, latitude. (unit: degree)\n",
    "- `longitude`: the geographic coordinate, longitude. (unit: degree)\n",
    "- `price`: house price per unit area (10000 New Taiwan Dollar/Ping,where Ping is a local unit of area, 1 Ping = 3.3 meter squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv('data/real_estate.csv')\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.1** \n",
    "<br> {points: 1}\n",
    "\n",
    "Create your $X$ and $y$ dataframes.   \n",
    "For the `X` dataframe make sure that you are not including `price`. Since our `y` (target) is the `price` column.        \n",
    "\n",
    "*Save each in the respective object names `X` and `y`*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "badca98689d7579f01f60e7f7d0b441a",
     "grade": false,
     "grade_id": "cell-ed966ed73ebc1218",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = None\n",
    "y = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "337dda35731fc8b7203ea2961226c867",
     "grade": true,
     "grade_id": "cell-11e500f7d2f30526",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_5_1(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.2** \n",
    "<br> {points: 0}\n",
    "\n",
    "Import `DummyRegressor()` from the `from sklearn.dummy` library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c5bb12892e98454c21d0ca65216d9d3",
     "grade": false,
     "grade_id": "cell-2dcee6a18047fadc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa3ea463a22d42e6143a17ea3ae4906d",
     "grade": true,
     "grade_id": "cell-c0010bc01a380bfc",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_5_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.3** \n",
    "<br> {points: 1}\n",
    "\n",
    "Build a Dummy Regressor with the `strategy` \"mean\" and name it `dummy_regr`. \n",
    "Train it on the variables `X` and `y` that we made in question 5.1. Predict on the `y` object and save the output in a object name `reg_predict`. \n",
    "Is the output what you expected? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40a608729887aa40ca7004e5ddff3d8e",
     "grade": false,
     "grade_id": "cell-267452394bafc485",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dummy_regr = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6001f7965a615729c32da04f1f9e4701",
     "grade": true,
     "grade_id": "cell-bb5aff1bc8d70ba7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_5_3(dummy_regr,reg_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.4** \n",
    "<br> {points: 1}\n",
    "\n",
    "To calculate the accuracy of regression models we need to see how close we were to the true value. We can use `.score()` like we did for the Dummy Classifier but this measure something different. The output of `.score()` for regressors returns the coefficient of determination of the prediction $R^2$. The best possible score is 1.0 and it can be a negative (because the model can be arbitrarily worse). \n",
    "\n",
    "Since a dummy regressor always predicts the mean value and disregards the input features(`X`), we expect a `.score()` of 0.0.\n",
    "\n",
    "Try it out on our real estate valuation data below and save the result in an object named `reg_score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c96dbf8b84cd1df934ada4865cc63d91",
     "grade": false,
     "grade_id": "cell-df43ab10d4970a00",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "reg_score = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "reg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01a874c802481c9646634864f5e51784",
     "grade": true,
     "grade_id": "cell-b5b2f97eb2026f60",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_5_4(reg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.5** \n",
    "<br> {points: 1}\n",
    "\n",
    "For baseline models, the features of the data are not taken into consideration when making predictions. This will change for other models that we will be learning.\n",
    "In fact, let's take a look at the feature `distance_station` which measures the distance a house is from a Mass Rapid Transit station vs the house price in the graph below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_plot = alt.Chart(housing_df, width=500, height=300).mark_circle(\n",
    "    opacity=0.7).encode(\n",
    "    alt.X('price:Q'),\n",
    "    alt.Y('distance_station:Q'))\n",
    "housing_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graph, do you think that the feature `distance_station` will help in the prediction of housing prices if we were to use models that are not baseline? \n",
    "\n",
    "A) Yes, since there seems to be a positive relationship between `price` and `distance_station`. \n",
    "\n",
    "B) Yes, since there seems to be a negative relationship between `price` and `distance_station`. \n",
    "\n",
    "C) No, since there doesn't seem to be a relationship between the feature and the target. \n",
    "\n",
    "D) No, since there seems to be a negative relationship between the feature `distance_station` and the target `price`\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer5_5`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "948d3a7b4fca9dc91540a6b2d7b3c5ce",
     "grade": false,
     "grade_id": "cell-6ceb24e39843684e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer5_5 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer5_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96bc0182146b1877fb7c69e83fea18ba",
     "grade": true,
     "grade_id": "cell-72fcb753a28473cc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_5_5(answer5_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Submitting \n",
    "\n",
    "Before submitting your assignment please do the following:\n",
    "\n",
    "- Read through your solutions\n",
    "- **Restart your kernel and clear output and rerun your cells from top to bottom** \n",
    "- Makes sure that none of your code is broken \n",
    "- Verify that the tests from the questions you answered have obtained the output \"Success\"\n",
    "\n",
    "This is a simple way to make sure that you are submitting all the variables needed to mark the assignment. This method should help avoid losing marks due to changes in your environment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "- Fertitily Diagnosis Dataset: - [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Fertility)\n",
    "\n",
    "*David Gil, Jose Luis Girela, Joaquin De Juan, M. Jose Gomez-Torres, and\n",
    "Magnus Johnsson. Predicting seminal quality with artificial intelligence\n",
    "methods. Expert Systems with Applications, 39(16):12564 â€“ 12573, 2012*\n",
    "\n",
    "- Real Estate Dataset - [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set)\n",
    "\n",
    "*Yeh, I. C., & Hsu, T. K. (2018). Building real estate valuation models with comparative approach through case-based reasoning. Applied Soft Computing, 65, 260-271.*\n",
    "\n",
    "\n",
    "- MDS DSCI 571 - Supervised Learning I - [MDS's GitHub website](https://github.com/UBC-MDS/DSCI_571_sup-learn-1) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
