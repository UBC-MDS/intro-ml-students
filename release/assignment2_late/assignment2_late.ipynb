{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Machine Learning  \n",
    "\n",
    "## Assignment 2: Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't learn technical subjects without hands-on practice. The assignments are an important part of the course. To submit this assignment you will need to make sure that you save your Jupyter notebook. \n",
    "\n",
    "Below are the links of 2 videos that explain:\n",
    "\n",
    "1. [How to save your Jupyter notebook](https://youtu.be/0aoLgBoAUSA) and,       \n",
    "2. [How to answer a question in a Jupyter notebook assignment](https://youtu.be/7j0WKhI3W4s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Learning Goals:\n",
    "\n",
    "By the end of the module, students are expected to:\n",
    "\n",
    "- Broadly describe how decision trees make predictions.\n",
    "- Use `DecisionTreeClassifier()` and `DecisionTreeRegressor()` to build decision trees using scikit-learn.\n",
    "- Use the `.fit()` and `.predict()` paradigm and use `.score()` method of ML models.\n",
    "- Explain the concept of decision boundaries.\n",
    "- Build a decision tree classifier on a real-world dataset and explore different hyperparameters of the classifier.\n",
    "- Explain how decision boundaries change with `max_depth`.\n",
    "- Build a decision tree regressor.\n",
    "\n",
    "This assignment covers [Module 2](https://ml-learn.mds.ubc.ca/en/module2) of the online course. You should complete this module before attempting this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any place you see `...`, you must fill in the function, variable, or data to complete the code. Substitute the `None` with your completed code and answers then proceed to run the cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the questions in this assignment will have hidden tests. This means that no feedback will be given as to the correctness of your solution. It will be left up to you to decide if your answer is sufficiently correct. These questions are worth 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed for this lab\n",
    "from hashlib import sha1\n",
    "\n",
    "import altair as alt\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import HTML\n",
    "from sklearn import tree\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import test_assignment2 as t\n",
    "\n",
    "from display_tree import display_tree\n",
    "alt.renderers.enable('html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Decision Tree Structure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1** <br> {points: 5}  \n",
    "\n",
    "<img src='static/tree.png' width=\"70%\"/>\n",
    "\n",
    "Label the 4 components of the decision tree diagram each with one of the possible values: \n",
    "\n",
    "- Stump\n",
    "\n",
    "- Root\n",
    "\n",
    "- Branch\n",
    "\n",
    "- Trunk\n",
    "\n",
    "- Node \n",
    "\n",
    "- Leaf\n",
    "\n",
    "- Bark\n",
    "\n",
    "- Nodule\n",
    "\n",
    "*Answer in the cell below by assigning the name of the decision tree as a string to the objects named `label_1`, `label_2`, `label_3` and `label_4`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28e7562705979ce21d0623c203b9e06a",
     "grade": false,
     "grade_id": "cell-86e07d016455e3e8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "label_1 = None\n",
    "label_2 = None\n",
    "label_3 = None\n",
    "label_4 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38f7dc23602087aa0d534bdc7a6482c5",
     "grade": true,
     "grade_id": "cell-8a674b835b989b8f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_1_1(label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "535bbfb51ea89ca4a1aacfc0b97066f0",
     "grade": true,
     "grade_id": "cell-cf63b8907f481c0f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_1_2(label_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1d7f87246cf51ae78cb0bb158561e02",
     "grade": true,
     "grade_id": "cell-21a19a87c7c52af2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'label_3' in globals(\n",
    "), \"Please make sure that your solution is named 'label_3'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9f2bc02497f14236ecb90297e276db4",
     "grade": true,
     "grade_id": "cell-afd585bc00c62c9c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_1_4(label_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** <br> {points: 1}  \n",
    "\n",
    "\n",
    "<img src='static/pman_tree.png' width=\"130%\"/>\n",
    "\n",
    "What would this decision tree predict for an observation with the following features?\n",
    "\n",
    "<br>\n",
    "\n",
    "```\n",
    "   attack  defense  sp_attack  sp_defense  speed  capture_rt  gen\n",
    "0    33      101        52         23        74      12        5\n",
    "```\n",
    "<br>\n",
    "\n",
    "*Save you answer as a string in an object named `pokemon_prediction`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6569bbbd6b41cb68f40e5ab27e6e2384",
     "grade": false,
     "grade_id": "cell-316bcedc8f318ef6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pokemon_prediction = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82629ad02536fd749d4f3baa652ace32",
     "grade": true,
     "grade_id": "cell-4cd4cb6c8653fe37",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_2(pokemon_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** <br> {points: 1}  \n",
    "\n",
    "What is the depth of the decision tree in **Question 1.2**?\n",
    "\n",
    "\n",
    "\n",
    "*Answer in the cell below with  your answer and assign it to an object called `tree_depth`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3734f7adc7c2740d49c634b40d9816e3",
     "grade": false,
     "grade_id": "cell-55927a8f679bdad7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tree_depth = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d610f24d525cc4ae81e2d45943cc4c32",
     "grade": true,
     "grade_id": "cell-41a8a7641bfea42f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_3(tree_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Tree Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have three different job offers with comparable salaries and job descriptions. You want to decide which one to accept, and you want to make this decision based on which job is likely to make you happy. Being a very systematic person, you come up with three features associated with the offers, which are important for your happiness: whether the colleagues are supportive, work-hour flexibility, and whether the company is a start-up or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_data = {\n",
    "    # Features\n",
    "    \"supportive_colleagues\": [1, 0, 0],\n",
    "    \"work_hour_flexibility\": [0, 0, 1],\n",
    "    \"start_up\": [0, 1, 1],\n",
    "    # Target\n",
    "    \"target\": [\"?\", \"?\", \"?\"],\n",
    "}\n",
    "\n",
    "offer_df = pd.DataFrame(offer_data)\n",
    "offer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you ask the following questions to some of your friends (who you think have similar notions of happiness) regarding their jobs:\n",
    "\n",
    "1. Do you have supportive colleagues? (1 for 'yes' and 0 for 'no')\n",
    "2. Do you have flexible work hours? (1 for 'yes' and 0 for 'no')\n",
    "3. Do you work for a start-up? (1 for 'start up' and 0 for 'non start up')\n",
    "4. Are you happy in your job? (happy or unhappy)\n",
    "\n",
    "You get the following data from this toy survey. Your goal is to train a machine learning model using this toy data and then use this model to predict which job is likely to make you happy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "happiness_data = {\n",
    "    # Features\n",
    "    \"supportive_colleagues\": [1, 1, 1, 0, 0, 1, 1, 0, 1, 0],\n",
    "    \"work_hour_flexibility\": [1, 1, 0, 1, 1, 0, 1, 0, 0, 0],\n",
    "    \"start_up\": [1, 0, 1, 0, 1, 0, 0, 1, 1, 0],\n",
    "    # Target\n",
    "    \"target\": [\n",
    "        \"happy\",\n",
    "        \"happy\",\n",
    "        \"happy\",\n",
    "        \"unhappy\",\n",
    "        \"unhappy\",\n",
    "        \"happy\",\n",
    "        \"happy\",\n",
    "        \"unhappy\",\n",
    "        \"unhappy\",\n",
    "        \"unhappy\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "train_df = pd.DataFrame(happiness_data)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** <br> {points: 2}  \n",
    "\n",
    "With this toy dataset, build a decision stump (decision tree with only 1 split) by hand by splitting on the condition `supportive_colleagues` == 1. \n",
    "\n",
    "What training accuracy would you get with this decision stump?\n",
    "\n",
    "Save the accuracy as a fraction in an object named `supportive_colleagues_acc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7292236427913c05c3f27ff96d55932",
     "grade": false,
     "grade_id": "cell-b273a46c48122d28",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "supportive_colleagues_acc = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d41f0d38baccebed18fc923f50aa4ff8",
     "grade": true,
     "grade_id": "cell-e68da65f049cb330",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'supportive_colleagues_acc' in globals(\n",
    "), \"Please make sure that your solution is named 'supportive_colleagues_acc'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2** \n",
    "<br> {points: 1}\n",
    "\n",
    "The idea of a machine learning algorithm is to *fit* the best model on the given training data, which is in the form of feature vectors (`X`) and their corresponding targets(`y`),  and then using this model to *predict* targets for new examples (represented with feature vectors).\n",
    "\n",
    "From `train_df`, create the feature table and save it in an object named `X` and the target in an object named `y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b8ed64454f48f9d0e7e876c595f3058",
     "grade": false,
     "grade_id": "cell-70545cc033402572",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = None\n",
    "y = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "405d393de7985dbd1899861650f73cd7",
     "grade": true,
     "grade_id": "cell-78887a980a05f8a6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_2(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3** \n",
    "<br> {points: 1}\n",
    "\n",
    "Build a decision tree named `toy_tree` and fit it on the toy data using `sklearn`'s [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06f663dba2ba918f4c953f79f45e6a45",
     "grade": false,
     "grade_id": "cell-25ec106a99d0aed6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "toy_tree = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b2a47c656384bb7f7deb6d03c45e402",
     "grade": true,
     "grade_id": "cell-d64f0e79c3f60336",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_3(toy_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4** <br> {points: 1}\n",
    "\n",
    "Visualize the trained decision tree using the function `display_tree` that we have imported from the `display_tree` library already. \n",
    "Save it in an object named `toy_displayed`.\n",
    "\n",
    "*Hint: use `?display_tree` to get more information about the function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94ae8b813cd38f22e3f551c5e267941f",
     "grade": false,
     "grade_id": "cell-e5fe770959fec147",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "toy_displayed = None\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "692d8d48e04a53ae3b6f862543cb760a",
     "grade": true,
     "grade_id": "cell-e0d146b1478af2ca",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_4(toy_displayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5** <br> {points: 1}\n",
    "\n",
    "Score the decision tree on the training data (`X` and `y`).\n",
    "Save the results in an object named `toy_score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eeb175f2c01f8a70101d333ff79dc4a0",
     "grade": false,
     "grade_id": "cell-cd274c5e40c8fc19",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "toy_score = None\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e61736bd72572aea72e38d6dfcb1d9b",
     "grade": true,
     "grade_id": "cell-4767e1fac2b98972",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_5(toy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6** <br> {points: 1}\n",
    "\n",
    "Predict on `X`. Add the results as a column named `predicted` in the `train_df` and name this new dataframe `predicted_train`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d75fb9020bdc38fa2625f6df341853e",
     "grade": false,
     "grade_id": "cell-134c27bb0dab898d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "predicted_train = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bde5f62d824451d5d08b50ec802e775",
     "grade": true,
     "grade_id": "cell-d364fe893db142e6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_6(predicted_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7** <br> {points: 1}\n",
    "\n",
    "Do you get perfect training accuracy? \n",
    "\n",
    "\n",
    "A) Yes, the model correctly predicts every single observation\n",
    "\n",
    "B) No, the model made a mistake likely because the decision tree wasn't complex enough.\n",
    "\n",
    "C) No, there are two examples in the dataset with exactly the same feature values but different targets so the model makes a mistake on one of them. \n",
    "\n",
    "D No, the model is randomly predicting and therefore it won't get every single example correct. \n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer2_7`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f57cb6b4f58a1154e8831f4fc20fc82",
     "grade": false,
     "grade_id": "cell-70ef59481896d9a6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_7 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98fdeee8898bc65824752abafe60f5d5",
     "grade": true,
     "grade_id": "cell-6bb3af682e405ef1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_7(answer2_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.8** <br> {points: 1}\n",
    "\n",
    "Create a feature table from the `offer_df` (We don't know the target value in this case). \n",
    "\n",
    "*Save this in an object named `offer_X`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1377d293a3db3afb1717eaee9e46567f",
     "grade": false,
     "grade_id": "cell-0e56f9e7d3451988",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "offer_X = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "124e6b6792e4b4c583fa903b2025e862",
     "grade": true,
     "grade_id": "cell-fd1dd525acb2556e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_8(offer_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.9** <br> {points: 1}\n",
    "\n",
    "Use the model `toy_tree` to predict which jobs from the `offer_df`, you will be happy working.  In other words, `predict` on `offer_X`.\n",
    "\n",
    "Add a column to the `offer_df` dataframe named `predicted` and save the whole dataframe in an object named `pred_offer_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fe9335236b56db33018e3cf72b9c2c7",
     "grade": false,
     "grade_id": "cell-5b44447ae8a53934",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pred_offer_df = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e1f59e53a77235fd6c8b05a6e858dca",
     "grade": true,
     "grade_id": "cell-c82446073aafe6f0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_9(pred_offer_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis and Decision Trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of the lab you'll be using a modified version of Kaggle's [Pokemon](https://www.kaggle.com/mlomuscio/pokemon?select=PokemonData.csv) dataset.\n",
    "The dataset contains a number of features of pokemon's strength and weaknesses:\n",
    "\n",
    "- `num`: ID for each Pokémon.\n",
    "- `name`: Name of each Pokémon.\n",
    "- `type`: Each Pokémon has a type, this determines weakness/resistance to attacks.\n",
    "- `hp`: Hit points, or health, defines how much damage a Pokémon can withstand before fainting.\n",
    "- `attack`: The base modifier for normal attacks (eg. Scratch, Punch).\n",
    "- `defense`: The base damage resistance against normal attacks.\n",
    "- `sp_atk`: Special attack, the base modifier for special attacks (e.g. fire blast, bubble beam).\n",
    "- `sp_def`: The base damage resistance against special attacks.\n",
    "- `total`: Sum of the `attack`, `defense`, `sp_atk`, and `sp_def` columns\n",
    "- `speed`: Determines which Pokémon attacks first each round.\n",
    "- `generation`: Number of generation.\n",
    "- `legendary`: 1 if Legendary Pokémon, 0 if not.\n",
    "\n",
    "In this question, our target is the `lengendary` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon = pd.read_csv('data/pokemon.csv')\n",
    "pokemon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1** <br> {points: 1}\n",
    "\n",
    "Show information of each feature using `pd.DataFrame.info` on `pokemon` and answer the question below.\n",
    "\n",
    "Select all that apply? \n",
    "\n",
    "\n",
    "A) There are `13` columns in the dataset.\n",
    "\n",
    "B) The legendary column is of Dtype `int64`.\n",
    "\n",
    "C) `5` columns have null values. \n",
    "\n",
    "D The name column is of Dtype `string`.\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer(s) between `\"\"` in a list, assign the correct answer to an object called `answer3_1`. For example [\"A', \"B\"] is a possible answer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e959e16c1f67d2e1a18a8dd519a4a238",
     "grade": false,
     "grade_id": "cell-a2db47fb095f7f28",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "490616bf3f9cfafdcdc1e4688981c22d",
     "grade": true,
     "grade_id": "cell-9bb18e26df9c9535",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_1(answer3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** <br> {points: 1}\n",
    "\n",
    "Show summary statistics of each feature using `pd.DataFrame.describe` on `pokemon` and store it into a variable called `pokemon_summary`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb723d6d35caad653bb110283390785b",
     "grade": false,
     "grade_id": "cell-eda75ea4a9bc77be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5cad38705f4bd7a2d670cbbf579db84",
     "grade": true,
     "grade_id": "cell-46d96af7948da033",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_2(pokemon_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3** <br> {points: 1}\n",
    "\n",
    "Using the Altair skills that you learned in [**Programming in Python for Data Science**](https://prog-learn.mds.ubc.ca/en/), Take the code below that we started for you (between the `'''`) and copy it into the solution cell. Fill in the blank areas (`....`) so that the code produces histograms for the following features (in order) that show the distribution of the feature values, separated for 0 and 1 target values. \n",
    "\n",
    "- `hp`\n",
    "- `attack`\n",
    "- `defense`\n",
    "- `sp_atk`\n",
    "- `sp_def`\n",
    "- `speed`\n",
    "- `total`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def plot_histogram(df,feature):\n",
    "    \"\"\"\n",
    "    plots a histogram of a decision trees feature\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature: str\n",
    "        the feature name\n",
    "    Returns\n",
    "    -------\n",
    "    altair.vegalite.v3.api.Chart\n",
    "        an Altair histogram \n",
    "    \"\"\"\n",
    "    histogram = alt.Chart(df).mark_bar(\n",
    "        opacity=0.7).encode(\n",
    "        alt.X(feature, bin=alt.Bin(maxbins=50)),\n",
    "        alt.Y('count()', stack=None),\n",
    "        alt.Color(....)).properties(\n",
    "        title= str.title(feature))\n",
    "    return ....\n",
    "\n",
    "feature_list = ....\n",
    "figure_dict = dict()\n",
    "for feature in .... :\n",
    "    figure_dict.update({feature:plot_histogram(....,feature)})\n",
    "figure_panel = alt.vconcat(*figure_dict.values())\n",
    "figure_panel\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9167ac87b23c59843f571c3adb7393bc",
     "grade": false,
     "grade_id": "cell-c76aa53afddb247a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62b23c7ccaacb83317bad0d8699e1822",
     "grade": true,
     "grade_id": "cell-2af5a0a27251f86b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_3(plot_histogram,figure_panel,figure_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4** \n",
    "<br> {points: 2}\n",
    "\n",
    "Which feature appears to be the most useful in differentiating the target classes?\n",
    "\n",
    "\n",
    "*Answer in the cell below by putting the feature name between `\"\"` and assign it to an object called `answer3_4`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43338a9ba8f0063fc703912226aecb36",
     "grade": false,
     "grade_id": "cell-3d33f2d26cb35d1c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer3_4 = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ec8a5e065dfd8bd71d8c01d993ccc88",
     "grade": true,
     "grade_id": "cell-6fa7879b55024120",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'answer3_4' in globals(\n",
    "), \"Please make sure that your solution is named 'answer3_4'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5** \n",
    "<br> {points: 1}\n",
    "\n",
    "Suppose for a particular feature, the histograms of that feature are identical for the two target classes. Does that mean the feature is not useful for predicting the target class?\n",
    "\n",
    "A) If the histograms are identical then there is no way differentiate each target value and so the feature is not useful. \n",
    "\n",
    "B) If the histograms are identical then we only need to use that feature for predicting the target value.\n",
    "\n",
    "C) If the histograms are identical, the feature might still be useful because it may be predictive in conjunction with other features.\n",
    "\n",
    "D) If the histograms are identical, the feature might still be useful but only with other models.  \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer3_5`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "365b420656384b8f16d4ea1fd6615934",
     "grade": false,
     "grade_id": "cell-b48cbd8184242f20",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer3_5 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b85e8279067ec33586ff5b17e8ef4d65",
     "grade": true,
     "grade_id": "cell-1f3265959c6bf456",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_5(answer3_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6** \n",
    "<br> {points: 1}\n",
    "\n",
    "Note that the dataset includes a categorical features labeled `type`. Do you think this feature could be useful in predicting whether the pokemon was legendary or not and would there be any difficulty in using it in our decision tree?\n",
    "\n",
    "A) Yes, it would be useful but adding categorical features into a model needs special attention.\n",
    "\n",
    "B) Yes, it would be useful and we shouldn't have any difficulty adding them into our model. \n",
    "\n",
    "C) No, We have enough features to predict with, the added `type` column would not add anything significant.\n",
    "\n",
    "D) No, and categorical features would need special attention to add to our model.\n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer3_6`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08fb041e1f61fa1597b0ce3e60d7a40b",
     "grade": false,
     "grade_id": "cell-85fd53a022f51dd4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer3_6 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8be70c1ea049413adb0e2865936c5ea8",
     "grade": true,
     "grade_id": "cell-f16d1e8638f8e8e3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_6(answer3_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1** \n",
    "<br> {points: 1}\n",
    "\n",
    "Create your $X$ and $y$ objects so that you X dataframe contains the columns: \n",
    "- `hp`\n",
    "- `attack`\n",
    "- `defense`\n",
    "- `sp_atk`\n",
    "- `sp_def`\n",
    "- `speed`\n",
    "- `total`\n",
    "- `generation`\n",
    "\n",
    "and your $y$ dataframe is the `legendary` column.\n",
    "\n",
    "*Save each in the respective object names `X` and `y`* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "044fa336c70f94ab3925bd6288a6eb60",
     "grade": false,
     "grade_id": "cell-45a7609572560222",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = None\n",
    "y = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eaa4bdf518f486df2054bc2968bf496d",
     "grade": true,
     "grade_id": "cell-3fa8141e49ac3579",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_1(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2** \n",
    "<br> {points: 3}\n",
    "\n",
    "In this exercise, you'll explore the `max_depth` hyperparameter within the range 1 to 15. See the [`DecisionTreeClassifier` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for more details.\n",
    "\n",
    "To do so, you will need to make a for loop for each value between 1-15 that: \n",
    "- Creates a model named `pokemon_tree`.\n",
    "- Sets the `max_depth` hyperparameter to the value it's iterating on. \n",
    "- Sets the argument `random_state=8`. \n",
    "- Fits each model on X and y.\n",
    "- Appends the model's score to the list depth_accuracy..\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aee5e8af13e74a1d971d00bdc265b5ab",
     "grade": false,
     "grade_id": "cell-fae89f1261704b9d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "depth_accuracy = list()\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "168fb2994d426e88d2d6fb664bdf8658",
     "grade": true,
     "grade_id": "cell-6283fe60af1dab79",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_2(depth_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3** <br>\n",
    "{points: 3} <br> \n",
    "\n",
    "Make a dataframe that contains the tree depth and scores and name it `depth_scores_df`\n",
    "\n",
    "It should look something like this:\n",
    "\n",
    "|    | max_depth      |   accuracy |\n",
    "|---:|:--------------|-----------:|\n",
    "|  0 | 1    |       # |\n",
    "|  1 | 2 |       # |\n",
    "|  2 | 3       |       # |\n",
    "| ...| ...|...|\n",
    "| 14 |15|#|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8a37b596e726e9ced2c264b391413eb",
     "grade": false,
     "grade_id": "cell-8c8afdbb26186293",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "depth_scores_df = None \n",
    "max_depth = list(range(1,16))\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16118a295eba5e8428c3a1b1bb5e0e55",
     "grade": true,
     "grade_id": "cell-5a53c6de3f6dbf9c",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_3(depth_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4** <br>\n",
    " {points: 1} <br>\n",
    " \n",
    "Using altair, make a `mark_line()` plot which displays the depth of the decision tree on the *x*-axis and the `depth_accuracy` on the *y*-axis.\n",
    "Make sure it has the dimensions `width=500, height=300`. Don't forget to give it a title and the plot `depth_acc_plot`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8edd376e3ea321f3829c7cb36a0d6524",
     "grade": false,
     "grade_id": "cell-78fc242b565e53ce",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "depth_acc_plot = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "\n",
    "depth_acc_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57ee3727e42d045e7ea18ec70ca8bb0f",
     "grade": true,
     "grade_id": "cell-372019731f861393",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_4(depth_acc_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the real estate data set that we saw in Assignment 1 and see if we can improve our $R^2$ from last time. \n",
    "\n",
    "For this question we are using a dataset obtained from [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set) that contains the market historical data of real estate valuation collected from Sindian District, New Taipei City in Taiwan.\n",
    "\n",
    "The columns in the dataset can be explained as follows: \n",
    "\n",
    "- `date`: the transaction date (for example, 2013.250=2013 March, 2013.500=2013 June, etc.)\n",
    "- `house_age`: the house age (unit: year)\n",
    "- `distance_station`: the distance to the nearest Mass Rapid Transit (MRT) station (unit: meter)\n",
    "- `num_stores`: the number of convenience stores in the living circle on foot (integer)(a ***living circle*** is a residential space with similar local characteristics, and daily behaviors)\n",
    "- `latitude`: the geographic coordinate, latitude. (unit: degree)\n",
    "- `longitude`: the geographic coordinate, longitude. (unit: degree)\n",
    "- `price`: house price per unit area (10000 New Taiwan Dollar/Ping,where Ping is a local unit of area, 1 Ping = 3.3 meter squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv('data/real_estate.csv')\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.1** \n",
    "<br> {points: 1}\n",
    "\n",
    "Create your $X$ and $y$ objects.   \n",
    "For the `X` dataframe make sure that you are not including `price`. Since our `y` (target) is the `price` column.        \n",
    "\n",
    "*Save each in the respective object names `X` and `y`* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f10c91510b7fd8a3ded726f8cbe4b9e6",
     "grade": false,
     "grade_id": "cell-02dcf742239390fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = None\n",
    "y = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26036fa54be8e5f677f1096c8687087f",
     "grade": true,
     "grade_id": "cell-a44e3702c7bb8014",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_5_1(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.2** \n",
    "<br> {points: 1}\n",
    "\n",
    "Build a Decision tree Regressor named `tree_reg`. Make sure to import DecisionTreeRegressor from  the sklearn.tree library. \n",
    "Train it on the variables `X` and `y` that we made in question 5.1. Save the score in a variable named `tree_score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aecf21b04194fc5b2650a5b0ff661a3e",
     "grade": false,
     "grade_id": "cell-2f6c9462cbd447dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tree_reg = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54b0d74a1195c700bb04b3799f757d52",
     "grade": true,
     "grade_id": "cell-d27128554c92c5f8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_5_2(tree_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.3** \n",
    "<br> {points: 2}\n",
    "\n",
    "Does the model do better than the Dummy Regressor we used in assignment 1? \n",
    "\n",
    "A) Both models Dummy Regressor and Decision Tree Regressor do about the same.\n",
    "\n",
    "B) Dummy Regressor does moderately better.\n",
    "\n",
    "C) Decision Tree Regressor does moderately better.\n",
    "\n",
    "D) Dummy Regressor does much better than the Decision Tree Regressor.\n",
    "\n",
    "E) Decision Tree Regressor does much better than the Dummy Regressor.\n",
    "\n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer5_3`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0683f31f8af84856ccb826efb2f15b4",
     "grade": false,
     "grade_id": "cell-6f58980f170cc823",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer5_3 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e717ff1e01a2b7f7ad5d310e69d0f8af",
     "grade": true,
     "grade_id": "cell-2a8b64d5335bdce1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'answer5_3' in globals(\n",
    "), \"Please make sure that your solution is named 'answer5_3'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Submitting \n",
    "\n",
    "Before submitting your assignment please do the following:\n",
    "\n",
    "- Read through your solutions\n",
    "- **Restart your kernel and clear output and rerun your cells from top to bottom** \n",
    "- Makes sure that none of your code is broken \n",
    "- Verify that the tests from the questions you answered have obtained the output \"Success\"\n",
    "\n",
    "This is a simple way to make sure that you are submitting all the variables needed to mark the assignment. This method should help avoid losing marks due to changes in your environment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "- Fertitily Diagnosis Dataset: - [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Fertility)\n",
    "\n",
    "*David Gil, Jose Luis Girela, Joaquin De Juan, M. Jose Gomez-Torres, and\n",
    "Magnus Johnsson. Predicting seminal quality with artificial intelligence\n",
    "methods. Expert Systems with Applications, 39(16):12564 â€“ 12573, 2012*\n",
    "\n",
    "- Real Estate Dataset - [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set)\n",
    "\n",
    "*Yeh, I. C., & Hsu, T. K. (2018). Building real estate valuation models with comparative approach through case-based reasoning. Applied Soft Computing, 65, 260-271.*\n",
    "\n",
    "\n",
    "- MDS DSCI 571 - Supervised Learning I - [MDS's GitHub website](https://github.com/UBC-MDS/DSCI_571_sup-learn-1) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
