{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Machine Learning  \n",
    "\n",
    "## Assignment 3: Splitting, Cross-Validation and the Fundamental Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't learn technical subjects without hands-on practice. The assignments are an important part of the course. To submit this assignment you will need to make sure that you save your Jupyter notebook. \n",
    "\n",
    "Below are the links of 2 videos that explain:\n",
    "\n",
    "1. [How to save your Jupyter notebook](https://youtu.be/0aoLgBoAUSA) and,       \n",
    "2. [How to answer a question in a Jupyter notebook assignment](https://youtu.be/7j0WKhI3W4s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Learning Goals:\n",
    "\n",
    "By the end of the module, students are expected to:\n",
    "\n",
    "- Use `train_test_split` for data splitting and explain the importance of shuffling during data splitting.\n",
    "- Explain the difference between train, validation, test, and \"deployment\" data.\n",
    "- Identify the difference between training error, validation error, and test error.\n",
    "- Do cross-validation with use cross_val_score and cross_validate to calculate cross-validation error.\n",
    "- Recognize overfitting, underfitting, and the fundamental tradeoff.\n",
    "- Follow the golden rule and identify the scenarios when it's violated.\n",
    "\n",
    "This assignment covers [Module 3](https://ml-learn.mds.ubc.ca/en/module3) of the online course. You should complete this module before attempting this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any place you see `...`, you must fill in the function, variable, or data to complete the code. Substitute the `None` with your completed code and answers then proceed to run the cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the questions in this assignment will have hidden tests. This means that no feedback will be given as to the correctness of your solution. It will be left up to you to decide if your answer is sufficiently correct. These questions are worth 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed for this lab\n",
    "from hashlib import sha1\n",
    "\n",
    "import altair as alt\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from IPython.display import HTML\n",
    "from sklearn import tree\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import test_assignment3 as t\n",
    "\n",
    "alt.renderers.enable('html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Splitting Your Data and Exploring Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question we are going to be working with a dataset modified from [Kaggle](https://www.kaggle.com/mlomuscio/sleepstudypilot). This data was collected from a survey-based study of the sleeping habits of individuals within the US. Note that these are the results of the pilot survey. \n",
    "\n",
    "\n",
    "We will be building a model using features from this data to predict if the an individual will have breakfast or not.\n",
    "\n",
    "\n",
    "For more information on the columns you can refer to [this website](https://www.kaggle.com/mlomuscio/sleepstudypilot). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df = pd.read_csv('data/sleep.csv')\n",
    "sleep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1** <br> {points: 0}  \n",
    "\n",
    "Before we do anything with our data we need to split it into our training set and test set. Import the necessary library to split your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7369d024d32b7aec90f51ca46e05b8de",
     "grade": false,
     "grade_id": "cell-4bc687ba4efdd230",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c01de58484c1c2496085c973c6b161d",
     "grade": true,
     "grade_id": "cell-d7952625b6fd95c6",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** <br> {points: 1}  \n",
    "\n",
    "Now split the `sleep_df` dataframe into `sleep_train` and `sleep_test` using a 80/20 train to test split. Make sure to set your `random_state` to 77."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "daab73f399e6bb768609744e30153534",
     "grade": false,
     "grade_id": "cell-489bdc31b84f8ab4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sleep_train, sleep_test = None, None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0ba0cc7fd5b47a9ab24e50c36902e78",
     "grade": true,
     "grade_id": "cell-17b53e96989f94ee",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_2(sleep_train,sleep_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** <br> {points: 1}  \n",
    "\n",
    "Using the `sleep_train` data, look at the summary statistics produced by `.describe()` and save the results in an object named `sleep_described`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0669f3c045ba639084f9b322e7a977a",
     "grade": false,
     "grade_id": "cell-1b01327301e7175c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sleep_described = None \n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c78ca9352e9df6afd02a7aa9206be49",
     "grade": true,
     "grade_id": "cell-7b8118a91db7b352",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_3(sleep_described)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4** <br> {points: 2}  \n",
    "\n",
    "What is the average number of hours the individuals in training set `sleep_train` sleep? Save your answer rounded to 2 decimal places in an object named `mean_hours`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "068b056f5cc72f9a859ff2d40e043f33",
     "grade": false,
     "grade_id": "cell-446c3e81e993a4cd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "mean_hours = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "\n",
    "mean_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e548bd07bf3254aa4e3274865096474",
     "grade": true,
     "grade_id": "cell-af1096f2ad063244",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'mean_hours' in globals(\n",
    "), \"Please make sure that your solution is named 'mean_hours'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5** <br> {points: 1}  \n",
    "\n",
    "What is the proportion of people who eat breakfast (`1` in the column) in `sleep_train`? Save your answer in an object named `break_prop`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9703faf9778ea6e75fa386adcb0f38c4",
     "grade": false,
     "grade_id": "cell-ee4a991fb320f3b1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "break_prop = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "\n",
    "break_prop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf7240dbcaaa2ee09ac5f65b7d3484cb",
     "grade": true,
     "grade_id": "cell-7f1ccc7292fd4c83",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1_5(break_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data splitting with Dummy and Random Forest Classifiers\n",
    "\n",
    "Recall that in machine learning what we care about is generalization; we want to build models that generalize well on unseen examples. One way to ensure this is by splitting the data into training data and test data, building and tuning the model only using the training data, and then doing the final assessing on the test data. \n",
    "\n",
    "We are going to use a new classifier called a [***Random Forest***](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). It's not pertinent that you know how this model works but for now just know that it is a more complex version of a decision tree and they share similar hyperparameters.\n",
    "\n",
    "Let's see how well our dummy and random forest classifiers do in comparison on the training and test sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** <br> {points: 1}  \n",
    "\n",
    "Split up the `sleep_df` dataframe by assigning the features to an object named `X` and the target column `Breakfast` to an object named `y`. \n",
    "\n",
    "Next, split the `X` and `y` dataset into a 80% train and 20% test set using [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) with `random_state=77`. \n",
    "\n",
    "Save the training features and target in objects named `X_train` and `y_train` respectively. Name the test features and target in objects `X_test` and `y_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50b5cb829743d47d2a4e1ee7e081e93c",
     "grade": false,
     "grade_id": "cell-0f7ff174c22cb624",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = None\n",
    "y = None\n",
    "X_train = None\n",
    "y_train = None\n",
    "X_test = None\n",
    "y_test = None\n",
    "\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3d3aa00fc4d319c8c7f9b49fd53b8d5",
     "grade": true,
     "grade_id": "cell-69fae1d0f9ee2461",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_1(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2** <br> {points: 1}  \n",
    "\n",
    "Build a `DummyClassifier` using `strategy = 'most_frequent'` and name it `dummy_model`.\n",
    "\n",
    "Train it on `X_train` and `y_train`. Score it on the train **and** test sets.\n",
    "\n",
    "Save the scores in an objects named `dummy_train` and `dummy_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d900b1fbdde8e01d99bb0b289225f47d",
     "grade": false,
     "grade_id": "cell-67361207e8f5757b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dummy_model = None\n",
    "dummy_train = None\n",
    "dummy_test = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2924631b869f8b8a3b4066b37edf722d",
     "grade": true,
     "grade_id": "cell-0f7984906bd1a9a3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_2(dummy_train, dummy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3** <br> {points: 1} \n",
    "\n",
    "Build a random forest classifier using (`RandomForestClassifier()`)  with `random_state=77` and name it `forest_model`.  \n",
    "\n",
    "Train it on `X_train` and `y_train`. Score it on the train **and** test sets.  \n",
    "\n",
    "Save the scores in an objects named `forest_train` and `forest_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2844f9a6b7ca165e9851d19704619b1",
     "grade": false,
     "grade_id": "cell-87b13a8ec9e7c3ad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "forest_model = None\n",
    "forest_train = None\n",
    "forest_test = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "117f3454721858e1fb0028e7ee0ef8dd",
     "grade": true,
     "grade_id": "cell-ea336f099b2901b6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_3(forest_train,forest_test,forest_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4** <br> {points: 2} \n",
    "\n",
    "Which model has the best training accuracy? \n",
    "\n",
    "A) `DummyClassifier`. \n",
    "\n",
    "B) `RandomForestClassifier`. \n",
    "\n",
    "C) Both A and B\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer2_4`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b57a430acc1ba5acbd2d35d71426d00",
     "grade": false,
     "grade_id": "cell-a8586e986a966bae",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_4 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer2_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6a8ddf6f364dbaa015e61718d690c8a",
     "grade": true,
     "grade_id": "cell-7dafee03cc1838c8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'answer2_4' in globals(\n",
    "), \"Please make sure that your solution is named 'answer2_4'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5** <br> {points: 1} \n",
    "\n",
    "Which model has the best test accuracy? \n",
    "\n",
    "A) `DummyClassifier`. \n",
    "\n",
    "B) `RandomForestClassifier`. \n",
    "\n",
    "C) Both A and B\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer2_5`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a578608c75d51592ddc022ca66f26ac7",
     "grade": false,
     "grade_id": "cell-494e417a872952e3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_5 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer2_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "982bd4687d88c0d75e0586ac2c3bf210",
     "grade": true,
     "grade_id": "cell-2fe846236581ee7b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_5(answer2_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6** <br> {points: 1} \n",
    "\n",
    "Which model is overfitting? \n",
    "\n",
    "A) `DummyClassifier`\n",
    "\n",
    "B) `RandomForestClassifier`\n",
    "\n",
    "C) Both A and B\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer2_6`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62395fbf1895ab70fc3cfb3c2aa3991d",
     "grade": false,
     "grade_id": "cell-6fba76357da5f920",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_6 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer2_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c27189b7b8e7c60f769c7ff97e2fbb6",
     "grade": true,
     "grade_id": "cell-55cfe6ccc9b36c62",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_6(answer2_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7** <br> {points: 1}  \n",
    "\n",
    "Do you expect the `DummyClassifier` to be sensitive to data splitting (Not just on this dataset)?  \n",
    "\n",
    "A) Yes since it's predicting the most occurring value and there is a chance that all of one category type  is in the test set which could change the most frequently occurring category in the training set.\n",
    "\n",
    "B) Yes, it's predicting a new value each time so it should be changing with splitting.\n",
    "\n",
    "C) No, The most occurring value will alway be the same.\n",
    "\n",
    "D) No, it's going to be static in the way it predicts.\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer2_7`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5fd799f17f6fa7f5b7e51cb3767297c",
     "grade": false,
     "grade_id": "cell-0dd76aab1ae3d3a3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_7 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer2_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e899106b72f021ab01d983b227bc307",
     "grade": true,
     "grade_id": "cell-22258cd4a4e03398",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2_7(answer2_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using a single train test split like we did in exercise 2, in this question 5-fold cross-validation using `cross_validate()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1** <br> {points: 0} \n",
    "\n",
    "Import `cross_validate` from the `sklearn` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eebceb6d9592b44d9b14419cfb5986a5",
     "grade": false,
     "grade_id": "cell-0a92a49f0918c20a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b11367b3b60d05634409e5344663a365",
     "grade": true,
     "grade_id": "cell-8976ad890e90bd18",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** <br> {points: 1} \n",
    "\n",
    "Create a new [***Random Forest Classifer***](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and name it, `cv_model`. Make sure to set `random_state=77`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "313c996d76ecf0677ec8b6c51ee5dbac",
     "grade": false,
     "grade_id": "cell-f3afb70a9fe0bcaf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cv_model = None\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca8f9b13c573885e83006343e7b7b254",
     "grade": true,
     "grade_id": "cell-965f1a2bc4db0d2b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_2(cv_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3** <br> {points: 1} \n",
    "\n",
    "Use cross-validation using `cross_validate()` on the `X` and `y` objects using the model `cv_model` and passing `return_train_score=True`.\n",
    "\n",
    "Save the result in an object named `cv_scores`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ca4260f264c782b52f3d95ec6d31ae1",
     "grade": false,
     "grade_id": "cell-90c1cb54ebae9bc7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cv_scores = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a29ef74fb720dc89ffbcc7498c1a6b7",
     "grade": true,
     "grade_id": "cell-61c9d452d769ad39",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_3(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4** <br> {points: 1} \n",
    "\n",
    "Convert `cv_scores` into a dataframe as save it as an object named `cv_scores_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f486149b57dc029b535e39b0431a61ab",
     "grade": false,
     "grade_id": "cell-99711c331ac3d90c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cv_scores_df = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f79fea1b9e0fecb2decd95d44f492df",
     "grade": true,
     "grade_id": "cell-e935c70832201a11",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_4(cv_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5** <br> {points: 1} \n",
    "\n",
    "What are the mean values of each column? Save your results as a series in a object named `mean_stats`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c10e1368a956d5a4fc314cb55d0c565",
     "grade": false,
     "grade_id": "cell-3afc4e3d90aab221",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e51495a08e5bdd9d810c0d810b91ade",
     "grade": true,
     "grade_id": "cell-a7e02cc826084b1b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3_5(mean_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6** <br> {points: 2} \n",
    "\n",
    "Are we violating the golden rule here?  \n",
    "\n",
    "A) No,  although test examples in one split are used as training example in another split, in each split, train and test examples are completely separate.\n",
    "\n",
    "B) No, cross-validation is a special case where this rule does not apply.\n",
    "\n",
    "C) Yes, train and test examples are mixed and therefore the golden rule is violated.\n",
    "\n",
    "D) Yes, the data examples are using features that are in both train and test data and therefore the golden rule is violated. \n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer3_6`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e43f5a2af07df4f3d2c1a87cbf2246d",
     "grade": false,
     "grade_id": "cell-3b7939374cea06f5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer3_6 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer3_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfc602654f5ea211689097db29b24dba",
     "grade": true,
     "grade_id": "cell-5d12bec3082be3b1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'answer3_6' in globals(\n",
    "), \"Please make sure that your solution is named 'answer3_6'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Assignment 2, we explored the `max_depth` hyperparameter of the `DecisionTreeClassifier`. In this exercise, you'll explore another hyperparameter, `min_samples_split` with the `RandomForestClassifier` which is also a decision tree hyperparameter. See the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for more details on this hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df = pd.read_csv('data/Sleep.csv')\n",
    "sleep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sleep_df.drop(columns = ['Breakfast'])\n",
    "y = sleep_df['Breakfast']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1** <br> {points: 1} \n",
    "\n",
    "Split `X` and `y` from the `sleep_df` dataset into a 80% train and 20% test subset using [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) and `random_state=77`. Make sure you split the features from the target in objects named `X_train`, `X_test`, `y_train`, `y_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98df3c0ebd1fc10c5eef6b083663c057",
     "grade": false,
     "grade_id": "cell-08a77e7ad3909471",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = None, None, None, None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81f6869113e3c6b2e2dc158d4f0b77b8",
     "grade": true,
     "grade_id": "cell-733689c7b705971d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_1(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2** <br> {points: 3} \n",
    "\n",
    "Let's explore the `min_samples_split` hyperparameter. \n",
    "\n",
    "In order to do this you will need to make a `for` loop that appends the results to the lists in the dictionary `results_dict` that we've provided for you below. \n",
    "\n",
    "Here we are giving you the steps on how to complete this question. \n",
    "\n",
    "Create a `for` loop that iterates over `min_sample_split` values from 2 to 50(inclusive) in increments of 2 (We've started this for you).\n",
    "\n",
    "Each iteration should:\n",
    "1. Create a `RandomForestClassifier` object with the hyperparameter `min_samples_split` changing at each iteration. Set a `random_state` to 77.\n",
    "2. Run 10-fold cross-validation with this `min_samples_split` using `cross_validate` to get the mean train and validation accuracies. Make sure to set `return_train_score=True` to get the training score in each fold. \n",
    "3. Appends the `min_samples_split` value to the list in the key `min_samples_split` of dictionary `results_dict`.\n",
    "4. Appends the mean `train_score` of the cross-validation folds to the list in the `mean_train_score` key. \n",
    "5. Appends the mean `test_score` of the cross-validation folds to the list in the `mean_cv_score` key. \n",
    "\n",
    "(Note that this may take a few minutes to execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5a78d975263d1dac01b632491a5cd29",
     "grade": false,
     "grade_id": "cell-bfd020dcdeccc028",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    \"min_samples_split\": [],\n",
    "    \"mean_train_score\": [],\n",
    "    \"mean_cv_score\": []}\n",
    "\n",
    "results_dict\n",
    "\n",
    "for sample_split in range(2,51, 2):\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90a3784fb26cee123c41507eb9e4aadd",
     "grade": true,
     "grade_id": "cell-f2a5b4e37b550ab3",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_2(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3** <br> {points: 1} \n",
    "\n",
    "Convert the dictionary `results_dict` into a dataframe named `results_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0fb853c333a5a8bc5cda86c61e9c603",
     "grade": false,
     "grade_id": "cell-a6418869ec080008",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "results_df = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "686caa833313125a9578e3900b532a77",
     "grade": true,
     "grade_id": "cell-0578e03de9dd590c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_3(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4** <br> {points: 1} \n",
    "\n",
    "Use `pd.melt()` to melt the columns `mean_train_score` and `mean_cv_score` in the `results_df`.  Use `var_name='score_type'` and `value_name='accuracy'` and name the new dataframe `plotting_source`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a623607f2b541f3fc2a80b7c7c320d4e",
     "grade": false,
     "grade_id": "cell-1625fc8a538d8265",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plotting_source = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "plotting_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2395a07baa8292d85835127e2551e6b5",
     "grade": true,
     "grade_id": "cell-80770b8e20d370fd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_4(plotting_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5** <br> {points: 1} \n",
    "\n",
    "Using Altair, make a `mark_line()` plot which displays the `min_samples_split` of the random forest model on the *x*-axis and the accuracy on the train and validation sets on the *y*-axis and don't forget to add `alt.Color(score_type)` to the `encode()` function after you specify `alt.X()` and `alt.y()`. \n",
    "\n",
    "Make sure it has the dimensions `width=500, height=300`. Don't forget to give it a title and the plot `mss_acc_plot`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c320d4b20d91ea71cb0c8a24e92a7170",
     "grade": false,
     "grade_id": "cell-11d4c7a29ce52ee7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "mss_acc_plot = None \n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "\n",
    "mss_acc_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c4baa64cdf4383f8494f91d2a4cf667",
     "grade": true,
     "grade_id": "cell-d19c2087a6909f02",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_5(mss_acc_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.6** <br> {points: 1} \n",
    "\n",
    "From your results, what `min_samples_split` would you pick in your final model? Save your answer in an object named `best_split`.\n",
    "\n",
    "*Hint: [<code>.idxmax()</code>](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.idxmax.html) may come in handy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "056e354b43f86f794ff67d6130424604",
     "grade": false,
     "grade_id": "cell-4f4e7c70262df146",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "best_split = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "549d44532ffca1c5cc08b2c2598f27e8",
     "grade": true,
     "grade_id": "cell-a66d20227c71b424",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_6(best_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.7** <br> {points: 1} \n",
    "\n",
    "Build a new random forest classifier name `best_model` with the best `min_samples_split` and fit it with `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7635ff8a0c889338e30988911f72c712",
     "grade": false,
     "grade_id": "cell-00e6676b5e3213a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "best_model = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7b5120f085ce1625f4dbb47524fc564",
     "grade": true,
     "grade_id": "cell-3261def2574d9f55",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_7(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.8** <br> {points: 1} \n",
    "\n",
    "Now carry out final assessment by calling `.score()` on `X_test` and `y_test`. Save you score in an object named `test_score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d295908f766c00fd1e65000c8ea38da",
     "grade": false,
     "grade_id": "cell-90a94d3b7883416d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_score = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0dec672b6d51085e202d1ad8ea44acee",
     "grade": true,
     "grade_id": "cell-88dbe188bc964f17",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_8(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.9** <br> {points: 2} \n",
    "\n",
    "Would you say that your test score is comparable to the cross-validation results?\n",
    "\n",
    "A) No, they are differ by over 20%.\n",
    "\n",
    "B) No, they differ by over 10%.\n",
    "\n",
    "C) Yes, the cross-validation scores were fairly representative.\n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer4_8`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f549df80e598609433f97d889bca0376",
     "grade": false,
     "grade_id": "cell-8568e5db8474d126",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_9 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer4_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6065c15112ca7cab42eb9704e505998a",
     "grade": true,
     "grade_id": "cell-ae343f43e3b3af81",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'answer4_9' in globals(\n",
    "), \"Please make sure that your solution is named 'answer4_9'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.10** <br> {points: 1} \n",
    "\n",
    "Why can't you simply pick the value of `min_samples_split` that does best on the training data?\n",
    "\n",
    "A) Because the model will likely overfit. \n",
    "\n",
    "B) Because the model will not generalize well on the validation data. \n",
    "\n",
    "C) Because the `min_samples_split` that does well on the train data will not necessarily do well on the test data. \n",
    "\n",
    "D) All of the above\n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer4_9`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2515e288c11b22587902a2230b878240",
     "grade": false,
     "grade_id": "cell-86753441745fd08c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_10 = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n",
    "answer4_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bcf06e93b2e27a64fb158a8babda218f",
     "grade": true,
     "grade_id": "cell-f68ffb36c5af030c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4_10(answer4_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Submitting \n",
    "\n",
    "Before submitting your assignment please do the following:\n",
    "\n",
    "- Read through your solutions\n",
    "- **Restart your kernel and clear output and rerun your cells from top to bottom** \n",
    "- Makes sure that none of your code is broken \n",
    "- Verify that the tests from the questions you answered have obtained the output \"Success\"\n",
    "\n",
    "This is a simple way to make sure that you are submitting all the variables needed to mark the assignment. This method should help avoid losing marks due to changes in your environment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "- Sleep Survey Dataset: - [Kaggle](https://www.kaggle.com/mlomuscio/sleepstudypilot)\n",
    "\n",
    "\n",
    "- MDS DSCI 571 - Supervised Learning I - [MDS's GitHub website](https://github.com/UBC-MDS/DSCI_571_sup-learn-1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
